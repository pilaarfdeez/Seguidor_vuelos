name: Run Scraper

on:
  push:
    branches:
      - main  # Workflow wird bei jedem Push zum main Branch ausgelöst
  pull_request:
    branches:
      - main  # Workflow wird auch bei Pull Requests zum main Branch ausgelöst
  schedule:
    - cron: "0 12 * * *" # Run daily at 12:00 UTC

jobs:
  build:
    runs-on: ubuntu-latest  # Wir verwenden ein Ubuntu-Image

    steps:
      # Schritt 1: Checkout des Codes
      - name: Checkout repository
        uses: actions/checkout@v4

      # Schritt 2: Setze Python und installiere Abhängigkeiten
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # Schritt 3: Installiere Abhängigkeiten
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      # Schritt 4: Setze Google Chrome und ChromeDriver für Headless-Betrieb
      # - name: Set up Google Chrome
      #   run: |
      #     sudo apt-get install -y wget curl unzip
      #     wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
      #     sudo dpkg -i google-chrome-stable_current_amd64.deb
      #     sudo apt --fix-broken install -y

      # # Schritt 5: Installiere ChromeDriver
      # - name: Set up ChromeDriver
      #   uses: browser-actions/setup-chromedriver@v2
      #   with:
      #     chromedriver-version: 'latest'  # Stellt sicher, dass die neueste Version von ChromeDriver verwendet wird

      - name: Install Chrome & ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          CHROME_VERSION=$(google-chrome --version | grep -oP '[0-9]+')
          CHROMEDRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_VERSION")
          wget -q -O chromedriver.zip "https://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip"
          unzip chromedriver.zip
          sudo mv chromedriver /usr/local/bin/
          chromedriver --version

      # Schritt 6: Füge Cookies aus GitHub Secrets hinzu
      - name: Write cookies to a file
        run: echo "${{ secrets.COOKIES_JSON }}" > data/cookies.json

      # Schritt 7: Führe das Scraper-Skript aus
      - name: Run scraper script
        run: |
          python main.py

      # Schritt 8: Speichere die JSON-Datei als Artefakt
      - name: Save the flight scraper output as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraper-output
          path: output/flights.json
